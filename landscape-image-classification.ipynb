{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Landscape Image classification using TensorFlow\n\n\nIn this project we will look at different images belonging to 6 different labels, train the model on those images and try to predict images with as high accuracy as possible.\n1. Firstly, we'll import usefull packages.\n1. Then, we'll load the data, before visualize and preprocess it.\n1. We'll try a simple CNN model and then we will evaluate its performances.\n1. We will then use pre trained model to address this challenge aswell.","metadata":{}},{"cell_type":"markdown","source":"# Import required Packages ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-04-15T23:31:21.705929Z","iopub.execute_input":"2022-04-15T23:31:21.706221Z","iopub.status.idle":"2022-04-15T23:31:21.712955Z","shell.execute_reply.started":"2022-04-15T23:31:21.706191Z","shell.execute_reply":"2022-04-15T23:31:21.711527Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\n\nIMAGE_SIZE = (150, 150)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:31:21.740749Z","iopub.execute_input":"2022-04-15T23:31:21.740948Z","iopub.status.idle":"2022-04-15T23:31:21.745722Z","shell.execute_reply.started":"2022-04-15T23:31:21.740924Z","shell.execute_reply":"2022-04-15T23:31:21.744811Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(class_names_label)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:31:21.769294Z","iopub.execute_input":"2022-04-15T23:31:21.769578Z","iopub.status.idle":"2022-04-15T23:31:21.775301Z","shell.execute_reply.started":"2022-04-15T23:31:21.769550Z","shell.execute_reply":"2022-04-15T23:31:21.774465Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Data\nWriting the data_loader function to load all the images along with the labels. In total we will be using around 17000 images with 14000 being used for training and  the rest for testing.","metadata":{}},{"cell_type":"code","source":"def data_loader():\n    datasets = ['../input/images/new_data/seg_train/seg_train', '../input/images/new_data/seg_test/seg_test']\n    output = []\n    \n    # Iterating through both the training and testing sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterating through each image in the folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Getting the path name of each image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Using openCV package to adjust the image to our required specifications\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Appending the image and its corresponding label\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:31:21.791394Z","iopub.execute_input":"2022-04-15T23:31:21.791677Z","iopub.status.idle":"2022-04-15T23:31:21.799536Z","shell.execute_reply.started":"2022-04-15T23:31:21.791650Z","shell.execute_reply":"2022-04-15T23:31:21.798852Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = data_loader()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:31:21.812591Z","iopub.execute_input":"2022-04-15T23:31:21.812877Z","iopub.status.idle":"2022-04-15T23:32:25.094886Z","shell.execute_reply.started":"2022-04-15T23:31:21.812849Z","shell.execute_reply":"2022-04-15T23:32:25.093965Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_images, train_labels = shuffle(train_images, train_labels, random_state=25)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:25.096588Z","iopub.execute_input":"2022-04-15T23:32:25.097728Z","iopub.status.idle":"2022-04-15T23:32:26.190809Z","shell.execute_reply.started":"2022-04-15T23:32:25.097683Z","shell.execute_reply":"2022-04-15T23:32:26.189858Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Exploring and Analyzing the dataset\n","metadata":{}},{"cell_type":"code","source":"n_train = train_images.shape[0]\nn_test = test_images.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Number of testing examples: {}\".format(n_test))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:26.192274Z","iopub.execute_input":"2022-04-15T23:32:26.192553Z","iopub.status.idle":"2022-04-15T23:32:26.198322Z","shell.execute_reply.started":"2022-04-15T23:32:26.192513Z","shell.execute_reply":"2022-04-15T23:32:26.197553Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n_, train_counts = np.unique(train_labels, return_counts=True)\n_, test_counts = np.unique(test_labels, return_counts=True)\npd.DataFrame({'train': train_counts,\n                    'test': test_counts}, \n             index=class_names\n            ).plot.bar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:26.200952Z","iopub.execute_input":"2022-04-15T23:32:26.201466Z","iopub.status.idle":"2022-04-15T23:32:26.482669Z","shell.execute_reply.started":"2022-04-15T23:32:26.201431Z","shell.execute_reply":"2022-04-15T23:32:26.481973Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(train_counts)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:26.483876Z","iopub.execute_input":"2022-04-15T23:32:26.484107Z","iopub.status.idle":"2022-04-15T23:32:26.488866Z","shell.execute_reply.started":"2022-04-15T23:32:26.484075Z","shell.execute_reply":"2022-04-15T23:32:26.487912Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"plt.pie(train_counts,\n        explode=(0, 0, 0, 0, 0, 0) , \n        labels=class_names,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:26.490387Z","iopub.execute_input":"2022-04-15T23:32:26.490718Z","iopub.status.idle":"2022-04-15T23:32:26.614378Z","shell.execute_reply.started":"2022-04-15T23:32:26.490683Z","shell.execute_reply":"2022-04-15T23:32:26.613490Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Scaling the data","metadata":{}},{"cell_type":"code","source":"train_images = train_images / 255.0 \ntest_images = test_images / 255.0","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:26.615738Z","iopub.execute_input":"2022-04-15T23:32:26.615984Z","iopub.status.idle":"2022-04-15T23:32:27.949371Z","shell.execute_reply.started":"2022-04-15T23:32:26.615949Z","shell.execute_reply":"2022-04-15T23:32:27.948556Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing images from the data\nWe can display a random image from the training set.","metadata":{}},{"cell_type":"code","source":"def show_random_image(class_names, images, labels):\n  \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:27.950742Z","iopub.execute_input":"2022-04-15T23:32:27.951012Z","iopub.status.idle":"2022-04-15T23:32:27.958166Z","shell.execute_reply.started":"2022-04-15T23:32:27.950975Z","shell.execute_reply":"2022-04-15T23:32:27.957106Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"show_random_image(class_names, train_images, train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:27.959612Z","iopub.execute_input":"2022-04-15T23:32:27.959934Z","iopub.status.idle":"2022-04-15T23:32:28.076064Z","shell.execute_reply.started":"2022-04-15T23:32:27.959841Z","shell.execute_reply":"2022-04-15T23:32:28.075232Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"We can also display more images to get a better view","metadata":{}},{"cell_type":"code","source":"def show_examples(class_names, images, labels):\n        \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(20):\n        plt.subplot(5,4,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:28.079375Z","iopub.execute_input":"2022-04-15T23:32:28.083331Z","iopub.status.idle":"2022-04-15T23:32:28.099044Z","shell.execute_reply.started":"2022-04-15T23:32:28.083269Z","shell.execute_reply":"2022-04-15T23:32:28.098207Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"show_examples(class_names, train_images, train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:28.100750Z","iopub.execute_input":"2022-04-15T23:32:28.101044Z","iopub.status.idle":"2022-04-15T23:32:29.021567Z","shell.execute_reply.started":"2022-04-15T23:32:28.101005Z","shell.execute_reply":"2022-04-15T23:32:29.020987Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Model Creation\n\n\n1. Build the model,\n1. Compile the model,\n1. Train / fit the data to the model,\n1. Evaluate the model on the testing set,\n\nWe will build a model using Conv2D, MaxPooling2D, Flatten layers, and using Relu and Softmax as activation functions. ","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:29.022889Z","iopub.execute_input":"2022-04-15T23:32:29.023345Z","iopub.status.idle":"2022-04-15T23:32:32.040343Z","shell.execute_reply.started":"2022-04-15T23:32:29.023308Z","shell.execute_reply":"2022-04-15T23:32:32.039592Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Using '*adam*' as **Optimizer** and '*sparse categorical crossentropy*' as **Loss function**, we will compile the model.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:32.041614Z","iopub.execute_input":"2022-04-15T23:32:32.042162Z","iopub.status.idle":"2022-04-15T23:32:32.057470Z","shell.execute_reply.started":"2022-04-15T23:32:32.042107Z","shell.execute_reply":"2022-04-15T23:32:32.056724Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Fitting the model to the training dataset.","metadata":{}},{"cell_type":"code","source":"model.fit(train_images, train_labels, batch_size=128, epochs=20, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:32:32.059017Z","iopub.execute_input":"2022-04-15T23:32:32.059313Z","iopub.status.idle":"2022-04-15T23:33:59.883536Z","shell.execute_reply.started":"2022-04-15T23:32:32.059259Z","shell.execute_reply":"2022-04-15T23:33:59.882830Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Evaluating the model performance on the test dataset","metadata":{}},{"cell_type":"code","source":"test_loss = model.evaluate(test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:33:59.885054Z","iopub.execute_input":"2022-04-15T23:33:59.885735Z","iopub.status.idle":"2022-04-15T23:34:02.370031Z","shell.execute_reply.started":"2022-04-15T23:33:59.885699Z","shell.execute_reply":"2022-04-15T23:34:02.362753Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"We have achieved an accuracy of 0.76 on the testing test.\n\nLet's select some random images and see how the classifier is evaluating them.","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(test_images)     # Vector of probabilities\npred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n\nshow_random_image(class_names, test_images, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:34:02.371277Z","iopub.execute_input":"2022-04-15T23:34:02.371557Z","iopub.status.idle":"2022-04-15T23:34:05.224751Z","shell.execute_reply.started":"2022-04-15T23:34:02.371518Z","shell.execute_reply":"2022-04-15T23:34:05.223691Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Error analysis\n\nLet's understand where the classifier is having trouble.","metadata":{}},{"cell_type":"code","source":"def show_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n   \n    BOO = (test_labels == pred_labels)\n    mislabeled_indices = np.where(BOO == 0)\n    mislabeled_images = test_images[mislabeled_indices]\n    mislabeled_labels = pred_labels[mislabeled_indices]\n\n    title = \"Some examples of mislabeled images by the classifier:\"\n    show_examples(class_names,  mislabeled_images, mislabeled_labels)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:34:05.227197Z","iopub.execute_input":"2022-04-15T23:34:05.227654Z","iopub.status.idle":"2022-04-15T23:34:05.239817Z","shell.execute_reply.started":"2022-04-15T23:34:05.227603Z","shell.execute_reply":"2022-04-15T23:34:05.238816Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"show_mislabeled_images(class_names, test_images, test_labels, pred_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:34:05.241911Z","iopub.execute_input":"2022-04-15T23:34:05.242787Z","iopub.status.idle":"2022-04-15T23:34:06.158479Z","shell.execute_reply.started":"2022-04-15T23:34:05.242737Z","shell.execute_reply":"2022-04-15T23:34:06.157832Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"CM = confusion_matrix(test_labels, pred_labels)\nax = plt.axes()\nsn.heatmap(CM, annot=True, \n           annot_kws={\"size\": 10}, \n           xticklabels=class_names, \n           yticklabels=class_names, ax = ax)\nax.set_title('Confusion matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T23:34:06.159612Z","iopub.execute_input":"2022-04-15T23:34:06.159960Z","iopub.status.idle":"2022-04-15T23:34:06.529606Z","shell.execute_reply.started":"2022-04-15T23:34:06.159927Z","shell.execute_reply":"2022-04-15T23:34:06.528934Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion: The classifier has trouble with 2 sets of similar images.\nIt has trouble with street and buildings. Given streets and buildings are in a near similar landscape, it is no coincidence. \nThe model also has trouble with sea, glacier and moutain images as well owing to similar colors and contrasts in the images. Forests are predicted accurately because of them being green and completely different from other landscapes.","metadata":{}}]}